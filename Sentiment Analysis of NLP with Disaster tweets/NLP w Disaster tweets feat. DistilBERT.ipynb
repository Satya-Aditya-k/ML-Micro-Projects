{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Disaster Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this Notebook I have worked on the Natural Language Processing with Disaster tweets in which we do the sentiment analysis of whether a tweet is a Disaster based or not by building models based on neural network model  **distilBERT** which is a smaller version of BERT, a state of the art Language Processing model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:27:35.076462Z",
     "iopub.status.busy": "2022-05-26T18:27:35.075959Z",
     "iopub.status.idle": "2022-05-26T18:27:49.935151Z",
     "shell.execute_reply": "2022-05-26T18:27:49.933692Z",
     "shell.execute_reply.started": "2022-05-26T18:27:35.076425Z"
    },
    "id": "B_vPK3FUEU6p",
    "outputId": "3ef2a44d-3371-4218-dda9-0792bce66e46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Dropout, Input\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "!pip install transformers\n",
    "#from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:29:32.854211Z",
     "iopub.status.busy": "2022-05-26T18:29:32.853771Z",
     "iopub.status.idle": "2022-05-26T18:29:32.916721Z",
     "shell.execute_reply": "2022-05-26T18:29:32.915692Z",
     "shell.execute_reply.started": "2022-05-26T18:29:32.854179Z"
    },
    "id": "1FSOcMVDFDzt"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We clean the tweet messages with the stop words*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:29:35.918555Z",
     "iopub.status.busy": "2022-05-26T18:29:35.917898Z",
     "iopub.status.idle": "2022-05-26T18:29:36.065209Z",
     "shell.execute_reply": "2022-05-26T18:29:36.063919Z",
     "shell.execute_reply.started": "2022-05-26T18:29:35.918520Z"
    },
    "id": "B0UXh7uVFEAL",
    "outputId": "786ea88f-daf6-488f-a279-fcdd6a69f4bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "def clean_stopwords_shortwords(w):\n",
    "    stopwords_list= stopwords.words('english')\n",
    "    words = w.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
    "    return \" \".join(clean_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The unicode strings are converted to ascii strings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:29:47.112323Z",
     "iopub.status.busy": "2022-05-26T18:29:47.111824Z",
     "iopub.status.idle": "2022-05-26T18:29:47.118860Z",
     "shell.execute_reply": "2022-05-26T18:29:47.117297Z",
     "shell.execute_reply.started": "2022-05-26T18:29:47.112290Z"
    },
    "id": "IszjAGHbGi7m"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All special characters are removed with the function below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:29:48.252754Z",
     "iopub.status.busy": "2022-05-26T18:29:48.251675Z",
     "iopub.status.idle": "2022-05-26T18:29:48.259647Z",
     "shell.execute_reply": "2022-05-26T18:29:48.258248Z",
     "shell.execute_reply.started": "2022-05-26T18:29:48.252684Z"
    },
    "id": "HDlQZEK3GnEz"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w=clean_stopwords_shortwords(w)\n",
    "    w=re.sub(r'@\\w+', '',w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:29:50.633759Z",
     "iopub.status.busy": "2022-05-26T18:29:50.633369Z",
     "iopub.status.idle": "2022-05-26T18:29:53.524206Z",
     "shell.execute_reply": "2022-05-26T18:29:53.523113Z",
     "shell.execute_reply.started": "2022-05-26T18:29:50.633728Z"
    },
    "id": "jGm0R0QTHtjt"
   },
   "outputs": [],
   "source": [
    "train['text'] = train['text'].map(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:29:54.289295Z",
     "iopub.status.busy": "2022-05-26T18:29:54.288694Z",
     "iopub.status.idle": "2022-05-26T18:29:54.302162Z",
     "shell.execute_reply": "2022-05-26T18:29:54.300984Z",
     "shell.execute_reply.started": "2022-05-26T18:29:54.289259Z"
    },
    "id": "pdme8IxdIM9u",
    "outputId": "bedadf01-e52a-40cf-a1d5-ad3f73052565"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               deeds reason earthquake may allah forgive\n",
       "1                      forest fire near ronge sask canada\n",
       "2       residents asked shelter place notified officer...\n",
       "3       people receive wildfires evacuation orders cal...\n",
       "4       got sent photo ruby alaska smoke wildfires pou...\n",
       "                              ...                        \n",
       "7608    two giant cranes holding bridge collapse nearb...\n",
       "7609    aria ahrary thetawniest control wild fires cal...\n",
       "7610                   utc volcano hawaii http zdtoyd ebj\n",
       "7611    police investigating bike collided car little ...\n",
       "7612    latest homes razed northern california wildfir...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The  tokenizer of the **distilbert-base-uncased** is imported from the transformers package and pretrained model is downloaded from the transformers package*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:29:56.761281Z",
     "iopub.status.busy": "2022-05-26T18:29:56.760631Z",
     "iopub.status.idle": "2022-05-26T18:30:00.838235Z",
     "shell.execute_reply": "2022-05-26T18:30:00.836860Z",
     "shell.execute_reply.started": "2022-05-26T18:29:56.761246Z"
    },
    "id": "LPen5jn3JFW5",
    "outputId": "592f98d3-d72f-452e-d458-cdf4439c51c0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fabd9d9c09340c28b8a265b7865bed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e9e97e04ba45d7998ed584e2d8fcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6265bf9845428f873fc14a1b66298e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "dbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:30:03.448035Z",
     "iopub.status.busy": "2022-05-26T18:30:03.447406Z",
     "iopub.status.idle": "2022-05-26T18:30:25.456205Z",
     "shell.execute_reply": "2022-05-26T18:30:25.454867Z",
     "shell.execute_reply.started": "2022-05-26T18:30:03.448000Z"
    },
    "id": "4RHJG5tRLiBE",
    "outputId": "21ebde24-5e52-4ae1-c5e2-db53b07b5f01"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49172598c7234a548e5fe8b1b8fd517d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:30:16.142848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-26 18:30:16.144653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-26 18:30:16.145687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-26 18:30:16.147065: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-26 18:30:16.147383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-26 18:30:16.148411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-26 18:30:16.149379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-26 18:30:22.251125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-26 18:30:22.252188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-26 18:30:22.253127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-26 18:30:22.253974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15047 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-05-26 18:30:22.619899: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "dbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:30:25.459763Z",
     "iopub.status.busy": "2022-05-26T18:30:25.458556Z",
     "iopub.status.idle": "2022-05-26T18:30:25.471147Z",
     "shell.execute_reply": "2022-05-26T18:30:25.467986Z",
     "shell.execute_reply.started": "2022-05-26T18:30:25.459715Z"
    },
    "id": "lW-IgR9GPEYN",
    "outputId": "9cd8833a-7911-4c59-bfa9-4cad952f2069"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 7613)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=32\n",
    "sentences=train['text']\n",
    "labels=train['target']\n",
    "len(sentences),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:30:27.431966Z",
     "iopub.status.busy": "2022-05-26T18:30:27.431529Z",
     "iopub.status.idle": "2022-05-26T18:30:27.440862Z",
     "shell.execute_reply": "2022-05-26T18:30:27.439695Z",
     "shell.execute_reply.started": "2022-05-26T18:30:27.431933Z"
    },
    "id": "vTsDK9YMPEev",
    "outputId": "8c7e0180-ddb8-47e9-f80d-1558b159720b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deeds', 'reason', 'earthquake', 'may', 'allah', 'forgive']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_tokenizer.tokenize(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:30:29.521429Z",
     "iopub.status.busy": "2022-05-26T18:30:29.520345Z",
     "iopub.status.idle": "2022-05-26T18:30:29.536656Z",
     "shell.execute_reply": "2022-05-26T18:30:29.535201Z",
     "shell.execute_reply.started": "2022-05-26T18:30:29.521366Z"
    },
    "id": "V1PpOykYPO2W",
    "outputId": "6deedbeb-f91c-4123-ae33-2c6da0579cb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 15616, 3114, 8372, 2089, 16455, 9641, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbert_inp=dbert_tokenizer.encode_plus(sentences[0],add_special_tokens = True,max_length =20,pad_to_max_length = True,truncation=True)\n",
    "dbert_inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The pretrained model needs two inputs, input id as tokens and attention masks, so every input needs to be padded, so this is done on a single sentence and we take a look at it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:30:33.657024Z",
     "iopub.status.busy": "2022-05-26T18:30:33.656596Z",
     "iopub.status.idle": "2022-05-26T18:30:33.784327Z",
     "shell.execute_reply": "2022-05-26T18:30:33.783115Z",
     "shell.execute_reply.started": "2022-05-26T18:30:33.656991Z"
    },
    "id": "x3YbpZyePY9o",
    "outputId": "bffaeae3-6e44-4333-9191-4e8b783549d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.modeling_tf_outputs.TFBaseModelOutput,\n",
       " TFBaseModelOutput(last_hidden_state=<tf.Tensor: shape=(1, 20, 768), dtype=float32, numpy=\n",
       " array([[[-0.17400928,  0.05031742, -0.25087613, ..., -0.007099  ,\n",
       "           0.32299748,  0.13289091],\n",
       "         [ 0.26510975,  0.2327715 ,  0.22081394, ...,  0.0275039 ,\n",
       "          -0.03581193,  0.10404292],\n",
       "         [-0.43689352,  0.18955605,  0.25972164, ..., -0.1418427 ,\n",
       "          -0.06919396,  0.14695333],\n",
       "         ...,\n",
       "         [ 0.0622292 ,  0.17262122,  0.17678715, ...,  0.15874153,\n",
       "          -0.04708431, -0.08581738],\n",
       "         [-0.11230349,  0.3852726 ,  0.34410006, ..., -0.10992186,\n",
       "          -0.05016324, -0.10346158],\n",
       "         [ 0.03663736,  0.2028245 ,  0.23218796, ...,  0.00811235,\n",
       "           0.00435018, -0.0390332 ]]], dtype=float32)>, hidden_states=None, attentions=None))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_inp=np.asarray(dbert_inp['input_ids'])\n",
    "mask_inp=np.asarray(dbert_inp['attention_mask'])\n",
    "out=dbert_model([id_inp.reshape(1,-1),mask_inp.reshape(1,-1)])\n",
    "type(out),out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUJjeBaBPZG_",
    "outputId": "bf503c5e-7542-4a97-8a98-01a435f8ab2a"
   },
   "outputs": [],
   "source": [
    "id_inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We create a NN model based by adding the distilbert layer to the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:30:36.779654Z",
     "iopub.status.busy": "2022-05-26T18:30:36.779108Z",
     "iopub.status.idle": "2022-05-26T18:30:36.793773Z",
     "shell.execute_reply": "2022-05-26T18:30:36.792484Z",
     "shell.execute_reply.started": "2022-05-26T18:30:36.779607Z"
    },
    "id": "xmol-rxvPyLD"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inps = Input(shape = (max_len,), dtype='int64')\n",
    "    masks= Input(shape = (max_len,), dtype='int64')\n",
    "    dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\n",
    "    dense = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\n",
    "    dropout= Dropout(0.5)(dense)\n",
    "    pred = Dense(2, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
    "    model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\n",
    "    print(model.summary())\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:30:38.946685Z",
     "iopub.status.busy": "2022-05-26T18:30:38.946280Z",
     "iopub.status.idle": "2022-05-26T18:30:45.500102Z",
     "shell.execute_reply": "2022-05-26T18:30:45.498835Z",
     "shell.execute_reply.started": "2022-05-26T18:30:38.946652Z"
    },
    "id": "9iFVDrBXPyUs",
    "outputId": "ca9dc199-1ec1-48cb-d4bc-1e4abac2819b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model (TFDistilB TFBaseModelOutput(la 66362880    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 768)          0           tf_distil_bert_model[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          393728      tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            1026        dropout_19[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 66,757,634\n",
      "Trainable params: 66,757,634\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We create input token ids and attention masks for all the sentences and take it into two variables **input_ids** and **attention_masks** variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:30:58.570788Z",
     "iopub.status.busy": "2022-05-26T18:30:58.570014Z",
     "iopub.status.idle": "2022-05-26T18:31:04.486499Z",
     "shell.execute_reply": "2022-05-26T18:31:04.485481Z",
     "shell.execute_reply.started": "2022-05-26T18:30:58.570755Z"
    },
    "id": "yW9gb74aQCyE",
    "outputId": "3a4c3993-69f8-4306-993a-05d62528e0c0"
   },
   "outputs": [],
   "source": [
    "input_ids=[]\n",
    "attention_masks=[]\n",
    "\n",
    "for sent in sentences:\n",
    "    dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "    input_ids.append(dbert_inps['input_ids'])\n",
    "    attention_masks.append(dbert_inps['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFBuCTlMQNV_",
    "outputId": "316c722b-a4c2-48d8-b0f4-c64f548f45d5"
   },
   "outputs": [],
   "source": [
    "  len(input_ids),len(attention_masks),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:31:08.706355Z",
     "iopub.status.busy": "2022-05-26T18:31:08.705550Z",
     "iopub.status.idle": "2022-05-26T18:31:08.728811Z",
     "shell.execute_reply": "2022-05-26T18:31:08.727562Z",
     "shell.execute_reply.started": "2022-05-26T18:31:08.706301Z"
    },
    "id": "9cpYz6u-QNY3",
    "outputId": "d9d09077-febe-42ae-c209-16d5c124309e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inp shape (6090, 32) Val input shape (1523, 32)\n",
      "Train label shape (6090,) Val label shape (1523,)\n",
      "Train attention mask shape (6090, 32) Val attention mask shape (1523, 32)\n"
     ]
    }
   ],
   "source": [
    "#train test split is done \n",
    "\n",
    "train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.2)\n",
    "\n",
    "print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:31:11.441136Z",
     "iopub.status.busy": "2022-05-26T18:31:11.440671Z",
     "iopub.status.idle": "2022-05-26T18:31:11.467187Z",
     "shell.execute_reply": "2022-05-26T18:31:11.465800Z",
     "shell.execute_reply.started": "2022-05-26T18:31:11.441061Z"
    },
    "id": "JV_bRhmBQC07"
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "\n",
    "model.compile(loss=loss,optimizer=optimizer, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:31:14.147858Z",
     "iopub.status.busy": "2022-05-26T18:31:14.147456Z",
     "iopub.status.idle": "2022-05-26T18:31:14.166247Z",
     "shell.execute_reply": "2022-05-26T18:31:14.164711Z",
     "shell.execute_reply.started": "2022-05-26T18:31:14.147826Z"
    },
    "id": "b2yVmH-hQa64"
   },
   "outputs": [],
   "source": [
    "#callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "model.compile(loss=loss,optimizer=optimizer, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:31:17.462920Z",
     "iopub.status.busy": "2022-05-26T18:31:17.461912Z",
     "iopub.status.idle": "2022-05-26T18:35:33.619644Z",
     "shell.execute_reply": "2022-05-26T18:35:33.618660Z",
     "shell.execute_reply.started": "2022-05-26T18:31:17.462883Z"
    },
    "id": "wu33j1z5Qa-N",
    "outputId": "6d68508a-a738-438b-873a-90ca55c286fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:31:17.554520: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/backend.py:4907: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 59s 130ms/step - loss: 5.8033 - accuracy: 0.7883 - val_loss: 4.9381 - val_accuracy: 0.8234\n",
      "Epoch 2/5\n",
      "381/381 [==============================] - 52s 138ms/step - loss: 4.2352 - accuracy: 0.8586 - val_loss: 3.7193 - val_accuracy: 0.8280\n",
      "Epoch 3/5\n",
      "381/381 [==============================] - 49s 128ms/step - loss: 3.0577 - accuracy: 0.9130 - val_loss: 2.8860 - val_accuracy: 0.8056\n",
      "Epoch 4/5\n",
      "381/381 [==============================] - 48s 127ms/step - loss: 2.1979 - accuracy: 0.9424 - val_loss: 2.3725 - val_accuracy: 0.8070\n",
      "Epoch 5/5\n",
      "381/381 [==============================] - 47s 124ms/step - loss: 1.5960 - accuracy: 0.9612 - val_loss: 2.0161 - val_accuracy: 0.8050\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([train_inp,train_mask],train_label,batch_size=16,epochs=5,validation_data=([val_inp,val_mask],val_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:36:01.541762Z",
     "iopub.status.busy": "2022-05-26T18:36:01.541215Z",
     "iopub.status.idle": "2022-05-26T18:36:01.558071Z",
     "shell.execute_reply": "2022-05-26T18:36:01.556719Z",
     "shell.execute_reply.started": "2022-05-26T18:36:01.541713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input_ids.shape\n",
    "attention_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:41:00.371045Z",
     "iopub.status.busy": "2022-05-26T18:41:00.370520Z",
     "iopub.status.idle": "2022-05-26T18:41:03.473102Z",
     "shell.execute_reply": "2022-05-26T18:41:03.471865Z",
     "shell.execute_reply.started": "2022-05-26T18:41:00.371004Z"
    },
    "id": "r9LVGkn7RmoV",
    "outputId": "377eb319-ea15-4982-a91c-a676fd73248f"
   },
   "outputs": [],
   "source": [
    "input_ids_test=[]\n",
    "attention_masks_test=[]\n",
    "\n",
    "\n",
    "for sent in test['text']:\n",
    "    dbert_inps_test=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "    input_ids_test.append(dbert_inps_test['input_ids'])\n",
    "    attention_masks_test.append(dbert_inps_test['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:41:31.217385Z",
     "iopub.status.busy": "2022-05-26T18:41:31.216860Z",
     "iopub.status.idle": "2022-05-26T18:41:38.652480Z",
     "shell.execute_reply": "2022-05-26T18:41:38.651421Z",
     "shell.execute_reply.started": "2022-05-26T18:41:31.217333Z"
    },
    "id": "Xu0OqUhwRmyV"
   },
   "outputs": [],
   "source": [
    "input_ids_test=np.asarray(input_ids_test)\n",
    "attention_masks_test=np.array(attention_masks_test)\n",
    "y_predict = model.predict([input_ids_test,attention_masks_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:41:43.479910Z",
     "iopub.status.busy": "2022-05-26T18:41:43.479380Z",
     "iopub.status.idle": "2022-05-26T18:41:43.486417Z",
     "shell.execute_reply": "2022-05-26T18:41:43.485295Z",
     "shell.execute_reply.started": "2022-05-26T18:41:43.479867Z"
    },
    "id": "nPaUAXnYSbKV"
   },
   "outputs": [],
   "source": [
    "predict = np.argmax(y_predict,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:41:48.853357Z",
     "iopub.status.busy": "2022-05-26T18:41:48.852800Z",
     "iopub.status.idle": "2022-05-26T18:41:48.861469Z",
     "shell.execute_reply": "2022-05-26T18:41:48.860384Z",
     "shell.execute_reply.started": "2022-05-26T18:41:48.853323Z"
    },
    "id": "MjhXoic7TPB3",
    "outputId": "e680dff3-b2cf-437c-8483-d29e84a4fe86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:42:00.873191Z",
     "iopub.status.busy": "2022-05-26T18:42:00.872727Z",
     "iopub.status.idle": "2022-05-26T18:42:00.880194Z",
     "shell.execute_reply": "2022-05-26T18:42:00.878734Z",
     "shell.execute_reply.started": "2022-05-26T18:42:00.873158Z"
    },
    "id": "IMLNEEiYTgAU",
    "outputId": "c3731bc4-a023-4fda-8069-3c083e90f697"
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({'id':test['id'].values,\n",
    "                             'target':predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-26T18:42:23.598621Z",
     "iopub.status.busy": "2022-05-26T18:42:23.598224Z",
     "iopub.status.idle": "2022-05-26T18:42:23.614303Z",
     "shell.execute_reply": "2022-05-26T18:42:23.613101Z",
     "shell.execute_reply.started": "2022-05-26T18:42:23.598588Z"
    },
    "id": "up8_wqnzTgIs"
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
